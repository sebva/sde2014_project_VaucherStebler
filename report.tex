\documentclass{paper}

%\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{url}
\graphicspath{ {images/} }
\usepackage{float}


% load package with ``framed'' and ``numbered'' option.
%\usepackage[framed,numbered,autolinebreaks,useliterate]{mcode}

% something NOT relevant to the usage of the package.
\setlength{\parindent}{0pt}
\setlength{\parskip}{18pt}






\usepackage[latin1]{inputenc} 
\usepackage[T1]{fontenc} 

\usepackage{listings} 
\lstset{% 
   language=Matlab, 
   basicstyle=\small\ttfamily, 
} 



\title{SDE Project: Hotspot Analysis}



\author{S\'{e}bastien Vaucher, 11-860-350\\Roger Stebler, 08-928-343}
% //////////////////////////////////////////////////


\begin{document}



\maketitle


% Add figures:
%\begin{figure}[t]
%%\begin{center}
%\quad\quad   \includegraphics[width=1\linewidth]{ass2}
%%\end{center}
%
%\label{fig:performance}
%\end{figure}

\section{Introduction}
The goal of this project was to find expensive methods in a software. To do that we ran a static analysis on a Java project and generated a call-graph using the CHA algorithm. The call-graph was then visualized by Roassal. Since static analysis does not represent the program during a real execution we also did a dynamic analysis using a homemade profiler and an off-the-shelf profiler. Then we compared all the results and drew some conclusions regarding the advantages and disadvantages of the different analysis techniques.\\


Note: This report does not include any results. It only describes design decisions we made during the project, problems we encountered and limitations.

\section{General information}

\paragraph{Selection of the program}\mbox{}\vspace{10pt}\\
We first tried to use an .mse file provided by Pangea. The smallest of those projects contained almost 2000 model classes. The problem was not the static analysis or the visualization but the dynamic analysis. We tried to instrument one of the smallest projects; the GanttProject. While running the dynamic analysis, we got a 500MB file representing the call-graph only by starting up the program. So we decided to use a smaller project and generate an .mse file by ourself.


Finally we found the program JFLAP with less than 1000 classes. JFLAP is a software to experiment with finite automata, turing mashines and several types of grammars.\footnote{\url{http://www.jflap.org}} So we created an .mse file for this program using VerveineJ and used that to do our static analysis.


\section{Static analysis}

\paragraph{Visualizing the call-graph}\mbox{}\vspace{10pt}\\
Since we are interested in finding long methods that are called often and are time consuming, we decided to only show the top 35 methods regarding LOC*NOIC in our visualization. Using the CHA algorithm we calculate the possible receivers of these methods and visualize the call-graph by showing the connections between the methods and the possible receiver classes.


The methods are displayed as red squares. Their sizes define the number of lines of code and their brightness show the number of incoming invocations. The classes are displayed as green circles. All the objects are aligned in two circles. The methods are laid out in the inner circle and the classes in the outer circle. Using this design we can clearly distinguish classes and methods.

\section{Dynamic analysis}

\paragraph{Homemade profiler}\mbox{}\vspace{10pt}\\
We developed a profiler in Java that is able to track methods calls of any Java program. It is packaged in a JAR file, implementing the Java agent API.\footnote{Classes in the \texttt{java.lang.instrument} package} Before loading a class file, the JVM will submit it to our component for modification.


If the class being modified is in a package satisfying some criteria,  we wrap each of its methods with two instructions using the Javassist library. The first is executed before and informs an object of ours that the program entered in a method. The second instruction is executed on exiting the method and informs the same object that the program exited the method. Using a combination of a stack and a list, we can extract the full call-graph of a given execution.


The generated call-graph is only completely accurate if all methods, including internal Java methods, are instrumented. This is not practically feasible because the execution time gets really high and some internal methods cannot be modified without crashing the JVM.


\paragraph{Off-the-shelf profiler}\mbox{}\vspace{10pt}\\
To profile JFLAP we tested \texttt{xprof} and \texttt{hprof}. \texttt{Xprof} is a really simple profiler, that does not provide much functionality. The data is split up for each thread and shows the number of invocations and the percentage of the runtime. \texttt{Hprof} did not run at all on our machines.

So we decided to use the shareware \texttt{JProfiler} to profile our program. It's a powerful tool that displays the collected data in real-time with a graphical representation. It can directly find bottlenecks in the code by ordering the methods using the total runtime (NOIC * T). It is also possible to collect information about the memory usage and some other Java-specific metrics. The main drawback about \texttt{JProfiler} is that it only shows a maximum of a hundred methods.



\end{document}